{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required modules and required dataset(here iris dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karthi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing of data to fit the network\n",
    "#seperating the data for test and train\n",
    "#one-hot encoding for label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_data=load_iris()\n",
    "data=iris_data.data\n",
    "data_prep=[]\n",
    "for each in data:\n",
    "    data_prep.append(np.reshape(each,(1,4)))\n",
    "data=data_prep\n",
    "target=iris_data.target\n",
    "targ=[]\n",
    "for each in target:\n",
    "    if each==0:\n",
    "        targ.append(np.array([[1,0,0]]))\n",
    "    elif each==1:\n",
    "        targ.append(np.array([[0,1,0]]))\n",
    "    else:\n",
    "        targ.append(np.array([[0,0,1]]))\n",
    "x_train,x_test,y_train,y_test=train_test_split(data,targ,test_size=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initialising the required tensorflow variables and placeholders\n",
    "#here i have epochs as 1000(you can use based on your data)\n",
    "#also initialisation of weights and bias for neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder('float',[1,4])\n",
    "y=tf.placeholder('float',[1,3])\n",
    "epoch=1000\n",
    "hidden_layer={\"weights\":tf.Variable(tf.random_normal([4,3])),\"bias\":tf.Variable(tf.random_normal([3]))}\n",
    "output={\"weights\":tf.Variable(tf.random_normal([3,3])),\"bias\":tf.Variable(tf.random_normal([3]))}\n",
    "ses=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating the neural network(here it contains input,one hidden and output layer )\n",
    "#activation function is sigmoid\n",
    "#we can add tf.nn.dropout() if we have large data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network(x):\n",
    "    \n",
    "    hl=tf.add(tf.matmul(x,hidden_layer[\"weights\"]),hidden_layer[\"bias\"])\n",
    "    h1=tf.nn.sigmoid(hl)\n",
    "    out=tf.add(tf.matmul(h1,output[\"weights\"]),output[\"bias\"])\n",
    "    out=tf.nn.sigmoid(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training phase\n",
    "#optimiser used adamoptimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x):\n",
    "    pred=neural_network(x)\n",
    "    cost=tf.reduce_mean(tf.square(pred-y))\n",
    "    optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
    "    ses.run(tf.global_variables_initializer())\n",
    "    print(\"weights and bias values before training\\nFor hidden layer one\")\n",
    "    print(ses.run(hidden_layer))\n",
    "    print(\"\\nFor output layer\")\n",
    "    print(ses.run(output))\n",
    "    for _ in range(0,epoch):\n",
    "        \n",
    "\n",
    "        for i in range(0,len(x_train)):\n",
    "            _,c=ses.run([optimizer,cost],feed_dict={x:x_train[i],y:y_train[i]})        \n",
    "    print(\"training completed\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing samples\n",
    "#printing final weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(x):\n",
    "    print(\"predicted   actual_output\")\n",
    "    for index in range(0,len(x_test)):    \n",
    "        val=ses.run(neural_network(x),feed_dict={x:x_test[index]})\n",
    "        maxi=max(val[0])#we can also use tf.argmax(val,1)\n",
    "        predict=[]\n",
    "        for i in range(0,3):\n",
    "            if maxi==val[0][i]:\n",
    "                predict.append(1)\n",
    "            else:\n",
    "                predict.append(0)\n",
    "        print(predict,y_test[index])\n",
    "    print(\"weights and bias values after training\\nFor hidden layer one\")\n",
    "    print(ses.run(hidden_layer))\n",
    "    print(\"\\nFor output layer\")\n",
    "    print(ses.run(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights and bias values before training\n",
      "For hidden layer one\n",
      "{'weights': array([[ 1.59768534,  1.32179105, -1.39354038],\n",
      "       [-0.10712165, -0.87775075,  0.34951234],\n",
      "       [ 0.04397516, -1.15375602, -1.1341486 ],\n",
      "       [ 0.69384015,  0.38983816, -0.57344157]], dtype=float32), 'bias': array([ 1.52473044,  0.03011509,  0.72239947], dtype=float32)}\n",
      "\n",
      "For output layer\n",
      "{'weights': array([[-1.03756964, -0.36068189,  1.49171793],\n",
      "       [-1.455742  ,  0.74590325, -0.18948466],\n",
      "       [ 0.12370484,  0.70590484, -0.94037479]], dtype=float32), 'bias': array([-0.10583455,  1.62069881, -1.71095347], dtype=float32)}\n",
      "training completed\n",
      "\n",
      "\n",
      "predicted   actual_output\n",
      "[0, 0, 1] [[0 0 1]]\n",
      "[0, 1, 0] [[0 1 0]]\n",
      "[1, 0, 0] [[1 0 0]]\n",
      "[1, 0, 0] [[1 0 0]]\n",
      "[1, 0, 0] [[1 0 0]]\n",
      "[0, 1, 0] [[0 1 0]]\n",
      "[1, 0, 0] [[1 0 0]]\n",
      "[1, 0, 0] [[1 0 0]]\n",
      "weights and bias values after training\n",
      "For hidden layer one\n",
      "{'weights': array([[-0.006882  ,  1.5590831 ,  0.02261473],\n",
      "       [-2.44188809, -0.46700358,  4.09692955],\n",
      "       [ 0.97669584, -1.87069714, -5.48639441],\n",
      "       [ 3.07773638, -1.27813315, -5.7258606 ]], dtype=float32), 'bias': array([-2.48491836,  2.22894573,  2.44265413], dtype=float32)}\n",
      "\n",
      "For output layer\n",
      "{'weights': array([[-13.47016907,  -7.66531229,   7.93613243],\n",
      "       [ -2.25285482,   8.58495903,  -8.43357182],\n",
      "       [ 19.39194107, -20.36994171, -17.85949326]], dtype=float32), 'bias': array([-6.49757051,  1.66390002, -1.88744044], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "train(x)\n",
    "test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
